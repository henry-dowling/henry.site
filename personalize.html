<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>What Happens When Models Stop Getting Smarter? – Henry Dowling</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/jpeg" href="favicon.jpg">
  <style>
    body {
      line-height: 1.4;
      font-size: 16px;
      padding: 0 10px;
      margin: 50px auto;
      max-width: 650px;
    }
    #maincontent {
      max-width: 42em;
      margin: 15 auto;
    }
  </style>
  </head>
  <body>
    <header>
      <h2><a href="index.html" style="color: inherit; text-decoration: none;">Henry Dowling</a>'s <a href="blog.html">Blog</a></h2>
    </header>
    <main>
      <h2>What happens when models stop getting smarter?</h2>

      <p>Most AI interactions today start with you explaining everything. This is annoying, especially if you've already explained everything somewhere else.</p>
      <p>This information isn’t usually a secret. What model car you drive, the link to the repo you’re working on, the names of your friends: all this info is easy to find from email, social media, search history, etc. </p> 
      <p>It’s not hard to imagine that this information could be programmatically given to an intelligence provider based on the context of the conversation. But this isn’t how things work currently.</p>

      <p><strong>LLM Response quality = intelligence + context quality.</strong></p>
      <p>In the post-GPT-5 world, LLM quality will hinge on how much high quality personal context you can give an intelligence provider.</p>
      <p>So, what happens if LLMs stop getting smarter? The way to win at response quality will be to have the highest <em>context quality</em>. The current battle for the most <em>intelligent</em> LLM will evolve into a battle for the <em>highest quality</em> LLM; i.e. the LLM with the best intelligence + context quality.</p>

      <h3>Who controls the personal context?</h3>
      <p>Who has access to the personal context dataset? It’s highly balkanized:</p>
      <ul>
        <li>notes you scribble to yourself</li>
        <li>browsing and search history</li>
        <li>content you watch on tiktok and other platforms</li>
        <li>discord servers and group chats</li>
        <li>calendars, emails, files, code repos, etc</li>
      </ul>

      <h3>We’ve seen this movie before</h3>
      <p>AI interactions will personalize at an industrial scale in the 2020s, similarly to content + ads in the 2010s.</p>
      <p>The last major AI wave—personalized recommendation algorithms—was mostly about finding context on someone and using it to generate high-quality outputs.</p>
      <p>Last decade, we built out massive infrastructure to enable personalized advertising that pulls information from every corner of a user’s online footprint.</p>
      <p><em>Aside—We expected this massive consolidation of information by a few key players (we called it “Big Data”) to fundamentally change the way society functioned, but it turned out to mostly enable better ads.</em></p>
      <p><em>Aside aside—A massive amount of data didn’t even seem to matter much in the AI wars—players like OpenAI and Anthropic had no data moat and still caught up to incumbents.</em></p>

      <p>AI providers will need to execute a similar-scale infrastructure buildout in order to win the war for best context quality.</p>

      <h3>Beyond on-demand chat</h3>
      <p>With enough context, AI will stop being an on-demand chat product. Right now, in order to get value out of AI, you need to prompt it. With sufficient context, AI should be able to answer your question before you even ask it:</p>
      <ul>
        <li>If it can see you’re stuck on a bug, it texts you what you’re missing.</li>
        <li>If you’re booking a vacation, it does deep research in the background to pre-empt your questions.</li>
      </ul>
      <p>As compute costs decrease (if models can’t get more intelligent, then costs have to go down), we’ll be able to invest more in <strong>Sleep Time Compute</strong> to create these pre-empting, magical interactions.</p>

      <h3>Who’s building this?</h3>
      <p>Me and Sam Liu. We’re building a notes app that lets AI take full advantage of the rich and high-quality context that you generate when you write notes to yourself to improve AI interactions.</p>

    </main>
  </body>
  </html>


